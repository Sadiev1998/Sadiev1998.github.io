---
title: Decentralized personalized federated min-max problems
subtitle: ""
publication_types:
  - "3"
authors:
  - Ekaterina Borodich
  - Aleksandr Beznosikov
  - Abdurakhmon Sadiev
  - Vadim Sushko
  - Nikolay Savelyev
  - Martin Takáč
  - Alexander Gasnikov
abstract: Personalized Federated Learning (PFL) has recently seen tremendous
  progress, allowing the design of novel machine learning applications to
  preserve the privacy of the training data. Existing theoretical results in
  this field mainly focus on distributed optimization for minimization problems.
  This paper is the first to study PFL for saddle point problems (which cover a
  broader class of optimization problems), allowing for a more rich class of
  applications requiring more than just solving minimization problems. In this
  work, we consider a recently proposed PFL setting with the mixing objective
  function, an approach combining the learning of a global model together with
  locally distributed learners. Unlike most previous work, which considered only
  the centralized setting, we work in a more general and decentralized setup
  that allows us to design and analyze more practical and federated ways to
  connect devices to the network. We proposed new algorithms to address this
  problem and provide a theoretical analysis of the smooth
  (strongly-)convex-(strongly-)concave saddle point problems in stochastic and
  deterministic cases. Numerical experiments for bilinear problems and neural
  networks with adversarial noise demonstrate the effectiveness of the proposed
  methods.
draft: false
tags: []
categories: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
summary: ""
lastmod: 2023-03-16T18:24:26+03:00
publication: "*arXiv preprint arXiv:2106.07289*"
featured: false
date: 2021-01-01
publishDate: 2023-03-16T15:24:26.130115Z
---
