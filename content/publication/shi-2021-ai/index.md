---
title: "AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods"
subtitle: ""
publication_types:
  - "3"
authors:
  - Zheng Shi
  - Abdurakhmon Sadiev
  - Nicolas Loizou
  - Peter Richtárik
  - Martin Takáč
abstract: We present AI-SARAH, a practical variant of SARAH. As a variant of
  SARAH, this algorithm employs the stochastic recursive gradient yet adjusts
  step-size based on local geometry. AI-SARAH implicitly computes step-size and
  efficiently estimates local Lipschitz smoothness of stochastic functions. It
  is fully adaptive, tune-free, straightforward to implement, and
  computationally efficient. We provide technical insight and intuitive
  illustrations on its design and convergence. We conduct extensive empirical
  analysis and demonstrate its strong performance compared with its classical
  counterparts and other state-of-the-art first-order methods in solving convex
  machine learning problems.
draft: false
url_pdf: https://arxiv.org/pdf/2102.09700v2.pdf
tags: []
categories: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
summary: ""
lastmod: 2023-03-16T18:24:25+03:00
publication: "*arXiv preprint arXiv:2102.09700*"
featured: false
date: 2022-01-31
publishDate: 2023-03-16T15:24:25.812Z
---
